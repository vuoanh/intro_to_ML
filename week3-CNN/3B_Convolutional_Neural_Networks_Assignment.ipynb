{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Assignment: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Duke Community Standard](http://integrity.duke.edu/standard.html): By typing your name below, you are certifying that you have adhered to the Duke Community Standard in completing this assignment.**\n",
    "\n",
    "Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "Adapt the CNN example for MNIST digit classfication from Notebook 3A. \n",
    "Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image ->  \n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) ->  \n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) ->  \n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) ->  \n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) -> flatten ->\n",
    "fully connected (256 hidden units) -> nonlinearity (ReLU) ->  \n",
    "fully connected (10 hidden units) -> softmax \n",
    "\n",
    "Note: The CNN model might take a while to train. Depending on your machine, you might expect this to take up to half an hour. If you see your validation performance start to plateau, you can kill the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab01b2496895460bb99d3637abd9ecbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d685b3902fc44ff9d19e3ca5a86b0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43785801228b4c0c982360de688533a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9842000007629395\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# load the data\n",
    "mnist_train = datasets.MNIST(root=\"./datasets/\", train=True, \n",
    "                             transform=transforms.ToTensor(),\n",
    "                             download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets/\", train=False,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, \n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "## Training\n",
    "# Model\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3, padding = 1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(32, 32, kernel_size=3, padding = 1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2),\n",
    "                                   nn.Conv2d(32, 64, kernel_size=3, padding = 1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(64, 64, kernel_size=3, padding = 1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(64*7*7, 256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(256, 10))\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = MNIST_CNN()\n",
    "\n",
    "#Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Iterate through train set minibatches\n",
    "for epoch in trange(1):\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        #Zero out the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        x = images\n",
    "        y = model(x)\n",
    "        loss = criterion(y, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatches\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        x = images\n",
    "        y = model(x)\n",
    "\n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "    \n",
    "print('Test accuracy: {}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a463a42349ba456aaaf3081aae011987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([100, 10])\n",
      "tensor(0.0371, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in tqdm(train_loader):\n",
    "    print(labels.size())\n",
    "    y = model(images)\n",
    "    print(y.size())\n",
    "    print(criterion(y, labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters in the model:\n",
      "Name: model.0.weight | Shape: torch.Size([32, 1, 3, 3])\n",
      "Name: model.0.bias | Shape: torch.Size([32])\n",
      "Name: model.2.weight | Shape: torch.Size([32, 32, 3, 3])\n",
      "Name: model.2.bias | Shape: torch.Size([32])\n",
      "Name: model.5.weight | Shape: torch.Size([64, 32, 3, 3])\n",
      "Name: model.5.bias | Shape: torch.Size([64])\n",
      "Name: model.7.weight | Shape: torch.Size([64, 64, 3, 3])\n",
      "Name: model.7.bias | Shape: torch.Size([64])\n",
      "Name: model.11.weight | Shape: torch.Size([256, 3136])\n",
      "Name: model.11.bias | Shape: torch.Size([256])\n",
      "Name: model.13.weight | Shape: torch.Size([10, 256])\n",
      "Name: model.13.bias | Shape: torch.Size([10])\n",
      "\n",
      "Total number of trainable parameters: 870,634\n"
     ]
    }
   ],
   "source": [
    "def print_model_weight_size(model):\n",
    "    print(\"Trainable parameters in the model:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"Name: {name} | Shape: {param.shape}\")\n",
    "    trainable_params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nTotal number of trainable parameters: {trainable_params_count:,}\")\n",
    "print_model_weight_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short answer\n",
    "\n",
    "1\\. How does the CNN compare in accuracy with yesterday's logistic regression and MLP models? How about training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "much higher accuracy but longer training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many trainable parameters are there in the CNN you built for this assignment?\n",
    "\n",
    "*Note: The total of trainable parameters counts each element in a tensor. For example, a weight matrix that is 10x5 has 50 trainable parameters.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "870,634"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. When would you use a CNN versus a logistic regression model or an MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs are for image/video datatype. MLPs work well with structured, tabular datasets. logistic regression is best used when the classes in the data are more or less linearly separable and the task can be solved in a predetermined, fixed number of dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
